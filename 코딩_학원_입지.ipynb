{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiHyun13/coding-academy-location-analysis/blob/main/%EC%BD%94%EB%94%A9_%ED%95%99%EC%9B%90_%EC%9E%85%EC%A7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¼ì´ë¸ŒëŸ¬ë¦¬"
      ],
      "metadata": {
        "id": "Kmp-V7e1gKXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# folium ì„¤ì¹˜ (ì²˜ìŒ 1íšŒë§Œ)\n",
        "!pip install folium\n",
        "!pip install geopy\n",
        "!pip install openpyxl\n",
        "!pip install haversine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_et15AfYRO8",
        "outputId": "16c62d71-e442-433b-f4fc-d9d7505d4f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from folium) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2025.7.14)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting haversine\n",
            "  Downloading haversine-2.9.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading haversine-2.9.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "from folium import plugins\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "from haversine import haversine, Unit"
      ],
      "metadata": {
        "id": "YCMDOM2TgR4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VM2hTDSgaRn",
        "outputId": "ef8853f2-ac6a-4162-ea38-ee01cbd3474d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. map class ì •ì˜   "
      ],
      "metadata": {
        "id": "t0B95a11ndHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APT0XaJ6X8Vr"
      },
      "outputs": [],
      "source": [
        "class CompetitorAnalysisMapper:\n",
        "    def __init__(self):\n",
        "        self.competitor_keywords = [\n",
        "            'ì½”ë”©', 'ì»´í“¨í„°', 'í”„ë¡œê·¸ë˜ë°', 'ì†Œí”„íŠ¸ì›¨ì–´', 'SW', 'ì¸ê³µì§€ëŠ¥','ë¡œë´‡', 'ê²Œì„', 'ì•±ê°œë°œ', 'ì›¹ê°œë°œ', 'IT'\n",
        "        ]\n",
        "\n",
        "        self.supporting_keywords = [\n",
        "            'ë…¼ìˆ ', 'ë…ì„œ', 'í† ë¡ ', 'ìŒì•…', 'íƒœê¶Œë„', 'ì²´ìœ¡ê´€', 'ë°”ë‘‘', 'ì‚°ìˆ˜', 'ì£¼ì‚°'\n",
        "        ]\n",
        "\n",
        "    def load_data(self, school_path, academy_path):\n",
        "        \"\"\"ë°ì´í„° ë¡œë“œ\"\"\"\n",
        "        self.schools_df = pd.read_csv(school_path, encoding='euc-kr')\n",
        "        self.academies_df = pd.read_csv(academy_path, encoding='utf-8')\n",
        "        print(f\"í•™êµ ë°ì´í„°: {len(self.schools_df)}ê°œ\")\n",
        "        print(f\"í•™ì› ë°ì´í„°: {len(self.academies_df)}ê°œ\")\n",
        "\n",
        "    def filter_by_region(self, region='ì„œìš¸íŠ¹ë³„ì‹œ'):\n",
        "        \"\"\"ì§€ì—­ë³„ í•„í„°ë§\"\"\"\n",
        "        # í•™êµ í•„í„°ë§ (ì´ˆì¤‘í•™êµë§Œ)\n",
        "        school_types = ['ì´ˆë“±í•™êµ', 'ì¤‘í•™êµ']\n",
        "        self.schools = self.schools_df[\n",
        "            (self.schools_df['ì‹œë„êµìœ¡ì²­ëª…'].str.contains(region, na=False)) &\n",
        "            (self.schools_df['í•™êµê¸‰êµ¬ë¶„'].isin(school_types)) &\n",
        "            (self.schools_df['ìš´ì˜ìƒíƒœ'] == 'ìš´ì˜') &\n",
        "            (self.schools_df['ìœ„ë„'].notna()) &\n",
        "            (self.schools_df['ê²½ë„'].notna()) &\n",
        "            (self.schools_df['í•™ìƒìˆ˜'].notna())\n",
        "        ].copy()\n",
        "\n",
        "        # í•™ì› í•„í„°ë§ (ê°œì› ìƒíƒœ, ì¢Œí‘œ ì¡´ì¬)\n",
        "        self.academies = self.academies_df[\n",
        "            (self.academies_df['ìœ„ë„'].notna()) &\n",
        "            (self.academies_df['ê²½ë„'].notna())\n",
        "        ].copy()\n",
        "\n",
        "        print(f\"{region} ì´ˆì¤‘í•™êµ: {len(self.schools)}ê°œ\")\n",
        "        print(f\"{region} í•™ì›: {len(self.academies)}ê°œ\")\n",
        "\n",
        "    def classify_supporting_academy(self, academy):\n",
        "        \"\"\"ìƒìƒì—…ì²´ ì„¸ë¶€ ë¶„ë¥˜\"\"\"\n",
        "        text = ' '.join([\n",
        "            str(academy.get('í•™ì›ëª…', '')),\n",
        "            str(academy.get('êµìŠµê³¼ì •ëª…', '')),\n",
        "            str(academy.get('ë¶„ì•¼ëª…', ''))\n",
        "        ]).lower()\n",
        "\n",
        "        if 'ìŒì•…' in text or 'í”¼ì•„ë…¸' in text or 'ë°”ì´ì˜¬ë¦°' in text:\n",
        "            return 'ìŒì•…'\n",
        "        elif 'íƒœê¶Œë„' in text or 'ì²´ìœ¡ê´€' in text:\n",
        "            return 'íƒœê¶Œë„/ì²´ìœ¡ê´€'\n",
        "        elif 'ë…¼ìˆ ' in text or 'ë…ì„œ' in text:\n",
        "            return 'ë…¼ìˆ /ë…ì„œ'\n",
        "        elif 'ë°”ë‘‘' in text or 'ì‚°ìˆ˜' in text or 'ì£¼ì‚°' in text:\n",
        "            return 'ë°”ë‘‘/ì£¼ì‚°'\n",
        "        else:\n",
        "            return 'ê¸°íƒ€'  # None ëŒ€ì‹  'ê¸°íƒ€' ë°˜í™˜\n",
        "\n",
        "    def classify_academies(self):\n",
        "        \"\"\"í•™ì› ë¶„ë¥˜: ê²½ìŸì—…ì²´ vs ìƒìƒì—…ì²´ (IT, AI ë¶€ë¶„ë§¤ì¹­ ë¬¸ì œ í•´ê²°)\"\"\"\n",
        "        import re\n",
        "\n",
        "        def is_exact_keyword_match(text, keyword):\n",
        "            \"\"\"ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ ë°©ì§€)\"\"\"\n",
        "            pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n",
        "            return bool(re.search(pattern, text.lower()))\n",
        "\n",
        "        def get_academy_type(row):\n",
        "            search_text = ' '.join([\n",
        "                str(row.get('í•™ì›ëª…', '')),\n",
        "                str(row.get('êµìŠµê³¼ì •ëª…', '')),\n",
        "                str(row.get('ë¶„ì•¼ëª…', '')),\n",
        "                str(row.get('êµìŠµê³„ì—´ëª…', ''))\n",
        "            ])\n",
        "\n",
        "            # ìƒìƒì—…ì²´ ë¨¼ì € ì²´í¬ (ìš°ì„ ìˆœìœ„)\n",
        "            for keyword in self.supporting_keywords:\n",
        "                if keyword.lower() in search_text.lower():\n",
        "                    return 'supporting'\n",
        "\n",
        "            # ê²½ìŸì—…ì²´ ì²´í¬ (ë¬¸ì œ í‚¤ì›Œë“œëŠ” ì •í™•í•œ ë§¤ì¹­)\n",
        "            for keyword in self.competitor_keywords:\n",
        "                if keyword.lower() in ['it', 'ai','ë©”ì´ì»¤']:\n",
        "                    # IT, AIëŠ” ë‹¨ì–´ ê²½ê³„ë¡œ ì •í™•íˆ ë§¤ì¹­\n",
        "                    if is_exact_keyword_match(search_text, keyword):\n",
        "                        return 'competitor'\n",
        "                else:\n",
        "                    # ë‚˜ë¨¸ì§€ëŠ” ê¸°ì¡´ ë°©ì‹ (ë¶€ë¶„ í¬í•¨)\n",
        "                    if keyword.lower() in search_text.lower():\n",
        "                        return 'competitor'\n",
        "\n",
        "            return 'other'\n",
        "\n",
        "        self.academies['academy_type'] = self.academies.apply(get_academy_type, axis=1)\n",
        "\n",
        "        # ë¶„ë¥˜ ê²°ê³¼ ë° ì¢Œí‘œ ì •ë³´ ì €ì¥\n",
        "        self.competitors = self.academies[self.academies['academy_type'] == 'competitor'].copy()\n",
        "        self.supporting_academies = self.academies[self.academies['academy_type'] == 'supporting'].copy()\n",
        "\n",
        "        # ì¢Œí‘œ ì»¬ëŸ¼ëª… í†µì¼ (x, y -> lat, lon)\n",
        "        self.competitors['lat'] = self.competitors['ìœ„ë„']\n",
        "        self.competitors['lon'] = self.competitors['ê²½ë„']\n",
        "        self.competitors['district'] = self.competitors['í–‰ì •êµ¬ì—­ëª…']\n",
        "        self.supporting_academies['lat'] = self.supporting_academies['ìœ„ë„']\n",
        "        self.supporting_academies['lon'] = self.supporting_academies['ê²½ë„']\n",
        "        self.supporting_academies['district'] = self.supporting_academies['í–‰ì •êµ¬ì—­ëª…']\n",
        "\n",
        "        print(f\"ê²½ìŸì—…ì²´: {len(self.competitors)}ê°œ\")\n",
        "        print(f\"ìƒìƒì—…ì²´: {len(self.supporting_academies)}ê°œ\")\n",
        "        print(f\"ê¸°íƒ€: {len(self.academies[self.academies['academy_type'] == 'other'])}ê°œ\")\n",
        "\n",
        "        # ë¶„ë¥˜ í™•ì¸ìš© ì¶œë ¥\n",
        "        print(\"\\nğŸ”´ ê²½ìŸì—…ì²´ ìƒ˜í”Œ:\")\n",
        "        for _, comp in self.competitors.head(3).iterrows():\n",
        "            print(f\"   - {comp['í•™ì›ëª…']} ({comp.get('êµìŠµê³¼ì •ëª…', 'N/A')})\")\n",
        "\n",
        "        print(\"\\nğŸŸ¢ ìƒìƒì—…ì²´ ìƒ˜í”Œ:\")\n",
        "        for _, sup in self.supporting_academies.head(3).iterrows():\n",
        "            print(f\"   - {sup['í•™ì›ëª…']} ({sup.get('êµìŠµê³¼ì •ëª…', 'N/A')})\")\n",
        "\n",
        "    def analyze_competitor_surroundings(self, radius_km=1.0):\n",
        "        \"\"\"ê²½ìŸì—…ì²´ ì£¼ë³€ í™˜ê²½ ë¶„ì„\"\"\"\n",
        "        surroundings_analysis = []\n",
        "\n",
        "        for idx, competitor in self.competitors.iterrows():\n",
        "            comp_lat, comp_lon = competitor['lat'], competitor['lon']\n",
        "\n",
        "            # ë°˜ê²½ ë‚´ í•™êµ ì°¾ê¸°\n",
        "            nearby_schools = []\n",
        "            for _, school in self.schools.iterrows():\n",
        "                distance = haversine((comp_lat, comp_lon), (school['ìœ„ë„'], school['ê²½ë„']),unit=Unit.KILOMETERS)\n",
        "                if distance <= radius_km:\n",
        "                    nearby_schools.append({\n",
        "                        'name': school['í•™êµëª…'],\n",
        "                        'type': school['í•™êµê¸‰êµ¬ë¶„'],\n",
        "                        'count': school['í•™ìƒìˆ˜'],\n",
        "                        'distance': distance\n",
        "                    })\n",
        "\n",
        "            # ë°˜ê²½ ë‚´ ìƒìƒì—…ì²´ ì°¾ê¸°\n",
        "            nearby_supporting = []\n",
        "            for _, academy in self.supporting_academies.iterrows():\n",
        "                distance = haversine((comp_lat, comp_lon), (academy['lat'], academy['lon']),unit=Unit.KILOMETERS)\n",
        "                if distance <= radius_km:\n",
        "                    # ìƒìƒì—…ì²´ íƒ€ì… ë¶„ë¥˜\n",
        "                    academy_type = self.classify_supporting_academy(academy)\n",
        "                    nearby_supporting.append({\n",
        "                        'name': academy['í•™ì›ëª…'],\n",
        "                        'type': academy_type,\n",
        "                        'distance': distance\n",
        "                    })\n",
        "\n",
        "            # ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
        "            analysis = {\n",
        "                'competitor_name': competitor['í•™ì›ëª…'],\n",
        "                'district': competitor.get('ë„ë¡œëª…ì£¼ì†Œ', '').split()[1] if len(str(competitor.get('ë„ë¡œëª…ì£¼ì†Œ', '')).split()) > 1 else 'Unknown',\n",
        "                'lat': comp_lat,\n",
        "                'lon': comp_lon,\n",
        "                'nearby_elementary': len([s for s in nearby_schools if s['type'] == 'ì´ˆë“±í•™êµ']),\n",
        "                'nearby_middle': len([s for s in nearby_schools if s['type'] == 'ì¤‘í•™êµ']),\n",
        "                'nearby_elem_students': sum(s['count'] for s in nearby_schools if s['type'] == 'ì´ˆë“±í•™êµ'),\n",
        "                'nearby_mid_students': sum(s['count'] for s in nearby_schools if s['type'] == 'ì¤‘í•™êµ'),\n",
        "                'nearby_music': len([s for s in nearby_supporting if 'ìŒì•…' in s['type']]),\n",
        "                'nearby_taekwondo': len([s for s in nearby_supporting if 'íƒœê¶Œë„/ì²´ìœ¡ê´€' in s['type']]),\n",
        "                'nearby_essay': len([s for s in nearby_supporting if 'ë…¼ìˆ ' in s['type']]),\n",
        "                'nearby_go': len([s for s in nearby_supporting if 'ë°”ë‘‘/ì£¼ì‚°' in s['type']]),\n",
        "                'total_schools': len(nearby_schools),\n",
        "                'total_supporting': len(nearby_supporting),\n",
        "                'school_details': nearby_schools,\n",
        "                'supporting_details': nearby_supporting\n",
        "            }\n",
        "\n",
        "            surroundings_analysis.append(analysis)\n",
        "\n",
        "        self.surroundings_df = pd.DataFrame(surroundings_analysis)\n",
        "        self.surroundings_df.to_csv('save1_surroundings_df.csv', index=False, encoding=\"utf-8-sig\")\n",
        "        return self.surroundings_df\n",
        "\n",
        "    def generate_environment_summary(self):\n",
        "        \"\"\"í™˜ê²½ ë¶„ì„ ìš”ì•½\"\"\"\n",
        "        if not hasattr(self, 'surroundings_df'):\n",
        "            print(\"ë¨¼ì € analyze_competitor_surroundings()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "            return\n",
        "\n",
        "        df = self.surroundings_df\n",
        "\n",
        "        print(\"=\"*50)\n",
        "        print(\"ğŸ¢ ê²½ìŸì—…ì²´ ì£¼ë³€ í™˜ê²½ ë¶„ì„ ê²°ê³¼\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        print(f\"\\nğŸ“ ë¶„ì„ ëŒ€ìƒ: {len(df)}ê°œ ê²½ìŸì—…ì²´ (ë°˜ê²½ 1km ê¸°ì¤€)\")\n",
        "\n",
        "        print(f\"\\nğŸ« ì£¼ë³€ í•™êµ í˜„í™©:\")\n",
        "        print(f\"   â€¢ í‰ê·  ì´ˆë“±í•™êµ: {df['nearby_elementary'].mean():.1f}ê°œ, í•™ìƒ ìˆ˜ {df['nearby_elem_students'].mean()}ëª…\")\n",
        "        print(f\"   â€¢ í‰ê·  ì¤‘í•™êµ: {df['nearby_middle'].mean():.1f}ê°œ, í•™ìƒ ìˆ˜ {df['nearby_mid_students'].mean()}ëª…\")\n",
        "        print(f\"   â€¢ í‰ê·  ì´ í•™êµ ìˆ˜: {df['total_schools'].mean():.1f}ê°œ\")\n",
        "\n",
        "        print(f\"\\nğŸ“ ì£¼ë³€ ìƒìƒì—…ì²´ í˜„í™©:\")\n",
        "        print(f\"   â€¢ í‰ê·  ìŒì•…í•™ì›: {df['nearby_music'].mean():.1f}ê°œ\")\n",
        "        print(f\"   â€¢ í‰ê·  íƒœê¶Œë„í•™ì›: {df['nearby_taekwondo'].mean():.1f}ê°œ\")\n",
        "        print(f\"   â€¢ í‰ê·  ë…¼ìˆ í•™ì›: {df['nearby_essay'].mean():.1f}ê°œ\")\n",
        "        print(f\"   â€¢ í‰ê·  ë°”ë‘‘/ì£¼ì‚°í•™ì›: {df['nearby_go'].mean():.1f}ê°œ\")\n",
        "        print(f\"   â€¢ í‰ê·  ì´ ìƒìƒì—…ì²´: {df['total_supporting'].mean():.1f}ê°œ\")\n",
        "\n",
        "        # ìµœì  í™˜ê²½ ê¸°ì¤€ ì„¤ì •\n",
        "        optimal_conditions = {\n",
        "            'min_elementary': df['nearby_elementary'].quantile(0.5),\n",
        "            'min_middle': df['nearby_middle'].quantile(0.5),\n",
        "            'min_elem_students': df['nearby_elem_students'].quantile(0.5),\n",
        "            'min_mid_students': df['nearby_mid_students'].quantile(0.5),\n",
        "            'min_supporting': df['total_supporting'].quantile(0.5)\n",
        "        }\n",
        "\n",
        "        print(f\"\\nâœ… ìµœì  ì…ì§€ ì¡°ê±´ (50%):\")\n",
        "        print(f\"   â€¢ ì´ˆë“±í•™êµ {optimal_conditions['min_elementary']:.0f}ê°œ ì´ìƒ, ì´ˆë“±í•™ìƒ ìˆ˜ {optimal_conditions['min_elem_students']:.0f}ëª… ì´ìƒ\")\n",
        "        print(f\"   â€¢ ì¤‘í•™êµ {optimal_conditions['min_middle']:.0f}ê°œ ì´ìƒ, ì¤‘í•™ìƒ ìˆ˜ {optimal_conditions['min_mid_students']:.0f}ëª… ì´ìƒ\")\n",
        "        print(f\"   â€¢ ìƒìƒì—…ì²´ {optimal_conditions['min_supporting']:.0f}ê°œ ì´ìƒ\")\n",
        "\n",
        "        return optimal_conditions\n",
        "\n",
        "    def find_opportunity_locations(self, optimal_conditions):\n",
        "        \"\"\"ì…ì§€ ê¸°íšŒ ë°œêµ´\"\"\"\n",
        "        # í•™êµ ì£¼ë³€ ì ì¬ ì§€ì—­ ì°¾ê¸°\n",
        "        opportunity_locations = []\n",
        "\n",
        "        # ê° í•™êµë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë°˜ê²½ 1km ë¶„ì„\n",
        "        for _, school in self.schools.iterrows():\n",
        "            school_lat, school_lon = school['ìœ„ë„'], school['ê²½ë„']\n",
        "\n",
        "            # ë°˜ê²½ ë‚´ ê²½ìŸì—…ì²´ ì²´í¬\n",
        "            nearby_competitors = 0\n",
        "            for _, comp in self.competitors.iterrows():\n",
        "                distance = haversine((school_lat, school_lon), (comp['lat'], comp['lon']),unit=Unit.KILOMETERS)\n",
        "                if distance <= 1.0:\n",
        "                    nearby_competitors += 1\n",
        "\n",
        "            # ê²½ìŸì—…ì²´ê°€ ì—†ê±°ë‚˜ ì ì€ ê³³ë§Œ ì„ ë³„\n",
        "            if nearby_competitors <= 1:  # 1ê°œ ì´í•˜\n",
        "                # ì£¼ë³€ í™˜ê²½ ë¶„ì„\n",
        "                nearby_schools = []\n",
        "                nearby_supporting = []\n",
        "                nearby_elem_students=[]\n",
        "                nearby_mid_students=[]\n",
        "\n",
        "                for _, other_school in self.schools.iterrows():\n",
        "                    distance = haversine((school_lat, school_lon), (other_school['ìœ„ë„'], other_school['ê²½ë„']),unit=Unit.KILOMETERS)\n",
        "                    if distance <= 1.0:\n",
        "                        nearby_schools.append(other_school['í•™êµê¸‰êµ¬ë¶„'])\n",
        "                        if other_school['í•™êµê¸‰êµ¬ë¶„']=='ì´ˆë“±í•™êµ':\n",
        "                          nearby_elem_students.append(other_school['í•™ìƒìˆ˜'])\n",
        "                        else:\n",
        "                          nearby_mid_students.append(other_school['í•™ìƒìˆ˜'])\n",
        "\n",
        "                for _, academy in self.supporting_academies.iterrows():\n",
        "                    distance = haversine((school_lat, school_lon), (academy['lat'], academy['lon']),unit=Unit.KILOMETERS)\n",
        "                    if distance <= 1.0:\n",
        "                        academy_type = self.classify_supporting_academy(academy)\n",
        "                        nearby_supporting.append(academy_type)\n",
        "\n",
        "                # ìµœì  ì¡°ê±´ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸\n",
        "                elementary_count = nearby_schools.count('ì´ˆë“±í•™êµ')\n",
        "                middle_count = nearby_schools.count('ì¤‘í•™êµ')\n",
        "                elementary_students_count = sum(nearby_elem_students)\n",
        "                middle_students_count = sum(nearby_mid_students)\n",
        "                supporting_count = len(nearby_supporting)\n",
        "\n",
        "                if (elementary_count >= optimal_conditions['min_elementary'] and\n",
        "                    middle_count >= optimal_conditions['min_middle'] and\n",
        "                    supporting_count >= optimal_conditions['min_supporting'] and\n",
        "                    elementary_students_count >= optimal_conditions['min_elem_students'] and\n",
        "                    middle_students_count >= optimal_conditions['min_mid_students']\n",
        "                    ):\n",
        "\n",
        "                    opportunity_locations.append({\n",
        "                        'center_school': school['í•™êµëª…'],\n",
        "                        'center_school_type': school['í•™êµê¸‰êµ¬ë¶„'],\n",
        "                        'district': school['ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ'].split()[1] if len(school['ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ'].split()) > 1 else 'Unknown',\n",
        "                        'lat': school_lat,\n",
        "                        'lon': school_lon,\n",
        "                        'nearby_elementary': elementary_count,\n",
        "                        'nearby_middle': middle_count,\n",
        "                        'nearby_elem_students': elementary_students_count,\n",
        "                        'nearby_mid_students': middle_students_count,\n",
        "                        'nearby_supporting': supporting_count,\n",
        "                        'nearby_competitors': nearby_competitors,\n",
        "                        'supporting_types': Counter(nearby_supporting)\n",
        "                    })\n",
        "\n",
        "        self.opportunities_df = pd.DataFrame(opportunity_locations)\n",
        "\n",
        "        print(f\"\\nğŸ¯ ë°œêµ´ëœ ì…ì§€ ê¸°íšŒ: {len(self.opportunities_df)}ê°œ ì§€ì—­\")\n",
        "\n",
        "        if len(self.opportunities_df) > 0:\n",
        "            print(f\"\\nğŸ“Š ê¸°íšŒ ì§€ì—­ ë¶„í¬:\")\n",
        "            district_counts = self.opportunities_df['district'].value_counts().head(10)\n",
        "            for district, count in district_counts.items():\n",
        "                print(f\"   â€¢ {district}: {count}ê°œ\")\n",
        "\n",
        "        return self.opportunities_df\n",
        "\n",
        "    def create_comprehensive_map(self):\n",
        "        \"\"\"ì¢…í•© ë¶„ì„ ì§€ë„ ìƒì„±\"\"\"\n",
        "        # ì„œìš¸ ì¤‘ì‹¬ ì§€ë„\n",
        "        m = folium.Map(\n",
        "            location=[37.5665, 126.9780],\n",
        "            zoom_start=11,\n",
        "            tiles='CartoDB positron'\n",
        "        )\n",
        "\n",
        "        # 1. í•™êµ ë ˆì´ì–´\n",
        "        school_group = folium.FeatureGroup(name=\"ğŸ« ì´ˆì¤‘í•™êµ\", show=True)\n",
        "        for _, school in self.schools.iterrows():\n",
        "            color = '#4285F4' if school['í•™êµê¸‰êµ¬ë¶„'] == 'ì´ˆë“±í•™êµ' else '#34A853'\n",
        "            folium.CircleMarker(\n",
        "                location=[school['ìœ„ë„'], school['ê²½ë„']],\n",
        "                radius=3,\n",
        "                popup=f\"ğŸ« {school['í•™êµëª…']}<br>{school['í•™êµê¸‰êµ¬ë¶„']}\",\n",
        "                color=color,\n",
        "                fill=True,\n",
        "                fillOpacity=0.6,\n",
        "                weight=1\n",
        "            ).add_to(school_group)\n",
        "\n",
        "        # 2. ê²½ìŸì—…ì²´ ë ˆì´ì–´\n",
        "        competitor_group = folium.FeatureGroup(name=\"ğŸ”´ ê²½ìŸì—…ì²´ (ì½”ë”©í•™ì›)\", show=True)\n",
        "        for _, comp in self.competitors.iterrows():\n",
        "            district = comp.get('ë„ë¡œëª…ì£¼ì†Œ', '').split()[1] if len(str(comp.get('ë„ë¡œëª…ì£¼ì†Œ', '')).split()) > 1 else 'Unknown'\n",
        "            popup_content = f\"\"\"\n",
        "            <div style=\"width: 200px;\">\n",
        "                <h4 style=\"color: red;\">ğŸ”´ ê²½ìŸì—…ì²´</h4>\n",
        "                <b>{comp['í•™ì›ëª…']}</b><br>\n",
        "                ê³¼ì •: {comp.get('êµìŠµê³¼ì •ëª…', 'N/A')}<br>\n",
        "                ì§€ì—­: {district}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            folium.Marker(\n",
        "                location=[comp['lat'], comp['lon']],\n",
        "                popup=folium.Popup(popup_content, max_width=250),\n",
        "                icon=folium.Icon(color='red', icon='laptop', prefix='fa'),\n",
        "                tooltip=comp['í•™ì›ëª…']\n",
        "            ).add_to(competitor_group)\n",
        "\n",
        "        # 3. ìƒìƒì—…ì²´ ë ˆì´ì–´ (ì „ì²´)\n",
        "        supporting_group = folium.FeatureGroup(name=f\"ğŸŸ¢ ìƒìƒì—…ì²´ ({len(self.supporting_academies)}ê°œ)\", show=False)\n",
        "        for _, academy in self.supporting_academies.iterrows():\n",
        "            academy_type = self.classify_supporting_academy(academy)\n",
        "            district = academy.get('ë„ë¡œëª…ì£¼ì†Œ', '').split()[1] if len(str(academy.get('ë„ë¡œëª…ì£¼ì†Œ', '')).split()) > 1 else 'Unknown'\n",
        "            color_map = {\n",
        "                'ìŒì•…': 'purple',\n",
        "                'íƒœê¶Œë„/ì²´ìœ¡ê´€': 'orange',\n",
        "                'ë…¼ìˆ /ë…ì„œ': 'red',\n",
        "                'ë°”ë‘‘/ì£¼ì‚°': 'pink',\n",
        "                'ê¸°íƒ€': 'gray'\n",
        "            }\n",
        "\n",
        "            folium.CircleMarker(\n",
        "                location=[academy['lat'], academy['lon']],\n",
        "                radius=1.5,  # ì¡°ê¸ˆ ë” ì‘ê²Œ\n",
        "                popup=f\"ğŸŸ¢ {academy['í•™ì›ëª…']}<br>{academy_type}<br>{district}\",\n",
        "                color=color_map.get(academy_type, 'gray'),\n",
        "                fill=True,\n",
        "                fillOpacity=0.6,\n",
        "                weight=0.5\n",
        "            ).add_to(supporting_group)\n",
        "\n",
        "        # 4. ê¸°íšŒ ì§€ì—­ ë ˆì´ì–´\n",
        "        if hasattr(self, 'opportunities_df') and len(self.opportunities_df) > 0:\n",
        "            opportunity_group = folium.FeatureGroup(name=\"â­ ì…ì§€ ê¸°íšŒ\", show=True)\n",
        "\n",
        "            for _, opp in self.opportunities_df.iterrows():\n",
        "                popup_content = f\"\"\"\n",
        "                <div style=\"width: 250px;\">\n",
        "                    <h4 style=\"color: gold;\">â­ ì…ì§€ ê¸°íšŒ</h4>\n",
        "                    <b>ì¤‘ì‹¬: {opp['center_school']}</b><br>\n",
        "                    ì§€ì—­: {opp['district']}<br>\n",
        "                    ì´ˆë“±í•™êµ: {opp['nearby_elementary']}ê°œ<br>\n",
        "                    ì´ˆë“±í•™ìƒ: {opp['nearby_elem_students']}ëª…<br>\n",
        "                    ì¤‘í•™êµ: {opp['nearby_middle']}ê°œ<br>\n",
        "                    ì¤‘í•™ìƒ: {opp['nearby_mid_students']}ëª…<br>\n",
        "                    ìƒìƒì—…ì²´: {opp['nearby_supporting']}ê°œ<br>\n",
        "                    ê²½ìŸì—…ì²´: {opp['nearby_competitors']}ê°œ\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "                folium.Marker(\n",
        "                    location=[opp['lat'], opp['lon']],\n",
        "                    popup=folium.Popup(popup_content, max_width=300),\n",
        "                    icon=folium.Icon(color='lightgreen', icon='star', prefix='fa'),\n",
        "                    tooltip=f\"ê¸°íšŒ ì§€ì—­: {opp['district']}\"\n",
        "                ).add_to(opportunity_group)\n",
        "\n",
        "            opportunity_group.add_to(m)\n",
        "\n",
        "        # ë ˆì´ì–´ ì¶”ê°€\n",
        "        school_group.add_to(m)\n",
        "        competitor_group.add_to(m)\n",
        "        supporting_group.add_to(m)\n",
        "\n",
        "        # ë ˆì´ì–´ ì»¨íŠ¸ë¡¤\n",
        "        folium.LayerControl(position='topright', collapsed=False).add_to(m)\n",
        "\n",
        "        # ë²”ë¡€\n",
        "        legend_html = '''\n",
        "        <div style=\"position: fixed; bottom: 50px; left: 50px; width: 280px;\n",
        "                    background-color: white; border:2px solid grey; z-index:9999;\n",
        "                    font-size:12px; padding: 10px;\">\n",
        "        <h4 style=\"margin-top:0;\">ê²½ìŸ ë¶„ì„ ì§€ë„</h4>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:#4285F4\"></i> ì´ˆë“±í•™êµ</p>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:#34A853\"></i> ì¤‘í•™êµ</p>\n",
        "        <p><i class=\"fa fa-map-marker\" style=\"color:red\"></i> ê²½ìŸì—…ì²´ (ì½”ë”©í•™ì›)</p>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:blue\"></i> ìƒìƒì—…ì²´ (ìŒì•…/ë°”ë‘‘ ë“±)</p>\n",
        "        <p><i class=\"fa fa-star\" style=\"color:lightgreen\"></i> ì…ì§€ ê¸°íšŒ ì§€ì—­</p>\n",
        "        </div>\n",
        "        '''\n",
        "        m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "        return m"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. ì‹¤í–‰ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "CaRUrUrcnm5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤í–‰ í•¨ìˆ˜ë“¤\n",
        "def run_complete_analysis():\n",
        "    \"\"\"ì „ì²´ ë¶„ì„ ì‹¤í–‰\"\"\"\n",
        "    analyzer = CompetitorAnalysisMapper()\n",
        "\n",
        "    # 1. ë°ì´í„° ë¡œë“œ\n",
        "    school_path = '/content/drive/MyDrive/ì½”ë”©í•™ì›/ì„œìš¸í•™êµë°ì´í„°_í•™ìƒìˆ˜.csv'\n",
        "    academy_path = '/content/drive/MyDrive/ì½”ë”©í•™ì›/ìµœì¢…í•™ì›.csv'\n",
        "    analyzer.load_data(school_path, academy_path)\n",
        "\n",
        "    # 2. ì§€ì—­ í•„í„°ë§\n",
        "    analyzer.filter_by_region('ì„œìš¸íŠ¹ë³„ì‹œ')\n",
        "\n",
        "    # 3. í•™ì› ë¶„ë¥˜, 4ì‚­ì œ\n",
        "    analyzer.classify_academies()\n",
        "\n",
        "    # 5. ê²½ìŸì—…ì²´ ì£¼ë³€ í™˜ê²½ ë¶„ì„\n",
        "    print(\"\\nğŸ” ê²½ìŸì—…ì²´ ì£¼ë³€ í™˜ê²½ ë¶„ì„ ì¤‘...\")\n",
        "    analyzer.analyze_competitor_surroundings(radius_km=1.0)\n",
        "\n",
        "    # 6. í™˜ê²½ ë¶„ì„ ìš”ì•½\n",
        "    optimal_conditions = analyzer.generate_environment_summary()\n",
        "\n",
        "    # 7. ì…ì§€ ê¸°íšŒ ë°œêµ´\n",
        "    print(\"\\nğŸ¯ ì…ì§€ ê¸°íšŒ ë°œêµ´ ì¤‘...\")\n",
        "    analyzer.find_opportunity_locations(optimal_conditions)\n",
        "\n",
        "    # 8. ì¢…í•© ì§€ë„ ìƒì„±\n",
        "    print(\"\\nğŸ—ºï¸ ì¢…í•© ë¶„ì„ ì§€ë„ ìƒì„± ì¤‘...\")\n",
        "    map_obj = analyzer.create_comprehensive_map()\n",
        "    map_obj.save('competitor_analysis_map.html')\n",
        "\n",
        "    print(\"\\nâœ… ë¶„ì„ ì™„ë£Œ!\")\n",
        "    print(\"ğŸ“ íŒŒì¼ ì €ì¥: competitor_analysis_map.html\")\n",
        "\n",
        "    return analyzer"
      ],
      "metadata": {
        "id": "W14xHmsni1Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "OorEuN5ct_YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_detailed_report(analyzer, save_files=True):\n",
        "    \"\"\"ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥\"\"\"\n",
        "    if not hasattr(analyzer, 'surroundings_df'):\n",
        "        print(\"ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "        return\n",
        "\n",
        "    # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ìƒì„±\n",
        "    report_content = []\n",
        "\n",
        "    report_content.append(\"=\"*60)\n",
        "    report_content.append(\"ğŸ“Š ì½”ë”©í•™ì› ê²½ìŸ ë¶„ì„ ë³´ê³ ì„œ\")\n",
        "    report_content.append(\"=\"*60)\n",
        "    report_content.append(f\"ğŸ“… ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    # 1. ê²½ìŸì—…ì²´ í˜„í™©\n",
        "    report_content.append(\"1ï¸âƒ£ ê²½ìŸì—…ì²´ í˜„í™©\")\n",
        "    report_content.append(f\"   ì´ {len(analyzer.competitors)}ê°œ ê²½ìŸì—…ì²´ í™•ì¸\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    # êµ¬ë³„ ë¶„í¬\n",
        "    district_dist = analyzer.competitors['district'].value_counts().head(10)\n",
        "    report_content.append(\"   ğŸ“ êµ¬ë³„ ê²½ìŸì—…ì²´ ë¶„í¬ (ìƒìœ„ 10ê°œ):\")\n",
        "    for district, count in district_dist.items():\n",
        "        report_content.append(f\"      {district}: {count}ê°œ\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    # 2. í‰ê·  í™˜ê²½ ë¶„ì„\n",
        "    df = analyzer.surroundings_df\n",
        "    report_content.append(\"2ï¸âƒ£ ê²½ìŸì—…ì²´ í‰ê·  ì…ì§€ í™˜ê²½ (ë°˜ê²½ 1km ê¸°ì¤€)\")\n",
        "    report_content.append(f\"   ğŸ« ì£¼ë³€ í•™êµ:\")\n",
        "    report_content.append(f\"      - í‰ê·  ì´ˆë“±í•™êµ: {df['nearby_elementary'].mean():.1f}ê°œ\")\n",
        "    report_content.append(f\"      - í‰ê·  ì¤‘í•™êµ: {df['nearby_middle'].mean():.1f}ê°œ\")\n",
        "    report_content.append(f\"      - í‰ê·  ì´ í•™êµ: {df['total_schools'].mean():.1f}ê°œ\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    report_content.append(f\"   ğŸ“ ì£¼ë³€ ìƒìƒì—…ì²´:\")\n",
        "    report_content.append(f\"      - í‰ê·  ìŒì•…í•™ì›: {df['nearby_music'].mean():.1f}ê°œ\")\n",
        "    report_content.append(f\"      - í‰ê·  íƒœê¶Œë„í•™ì›: {df['nearby_taekwondo'].mean():.1f}ê°œ\")\n",
        "    report_content.append(f\"      - í‰ê·  ë…¼ìˆ í•™ì›: {df['nearby_essay'].mean():.1f}ê°œ\")\n",
        "    report_content.append(f\"      - í‰ê·  ë°”ë‘‘í•™ì›: {df['nearby_go'].mean():.1f}ê°œ\")\n",
        "    report_content.append(f\"      - í‰ê·  ì´ ìƒìƒì—…ì²´: {df['total_supporting'].mean():.1f}ê°œ\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    # 3. ìµœì  ì…ì§€ ì¡°ê±´\n",
        "    optimal_conditions = {\n",
        "        'min_elementary': df['nearby_elementary'].quantile(0.50),\n",
        "        'min_middle': df['nearby_middle'].quantile(0.50),\n",
        "        'min_supporting': df['total_supporting'].quantile(0.50),\n",
        "        'min_elem_students': df['nearby_elem_students'].quantile(0.50),\n",
        "        'min_mid_students': df['nearby_mid_students'].quantile(0.50)\n",
        "    }\n",
        "\n",
        "    report_content.append(\"   âœ… ìµœì  ì…ì§€ ì¡°ê±´ (ê²½ìŸì—…ì²´ 50% ìˆ˜ì¤€):\")\n",
        "    report_content.append(f\"      - ì´ˆë“±í•™êµ {optimal_conditions['min_elementary']:.0f}ê°œ ì´ìƒ, í•™ìƒ {optimal_conditions['min_elem_students']} ëª… ì´ìƒ\")\n",
        "    report_content.append(f\"      - ì¤‘í•™êµ {optimal_conditions['min_middle']:.0f}ê°œ ì´ìƒ,  í•™ìƒ {optimal_conditions['min_mid_students']} ëª… ì´ìƒ\")\n",
        "    report_content.append(f\"      - ìƒìƒì—…ì²´ {optimal_conditions['min_supporting']:.0f}ê°œ ì´ìƒ\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    # 4. ì…ì§€ ê¸°íšŒ\n",
        "    if hasattr(analyzer, 'opportunities_df'):\n",
        "        report_content.append(\"3ï¸âƒ£ ì…ì§€ ê¸°íšŒ ì§€ì—­\")\n",
        "        report_content.append(f\"   ğŸ¯ ì´ {len(analyzer.opportunities_df)}ê°œ ê¸°íšŒ ì§€ì—­ ë°œêµ´\")\n",
        "        report_content.append(\"      (ìµœì  ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ ê²½ìŸì—…ì²´ê°€ 1ê°œ ì´í•˜ì¸ ì§€ì—­)\")\n",
        "        report_content.append(\"\")\n",
        "\n",
        "        if len(analyzer.opportunities_df) > 0:\n",
        "            opp_districts = analyzer.opportunities_df['district'].value_counts().head(10)\n",
        "            report_content.append(\"   ğŸ“ êµ¬ë³„ ê¸°íšŒ ì§€ì—­ ë¶„í¬:\")\n",
        "            for district, count in opp_districts.items():\n",
        "                report_content.append(f\"      {district}: {count}ê°œ\")\n",
        "            report_content.append(\"\")\n",
        "\n",
        "            # ìƒìœ„ ê¸°íšŒ ì§€ì—­ ìƒì„¸ ì •ë³´\n",
        "            top_opportunities = analyzer.opportunities_df.nlargest(10, 'nearby_supporting')\n",
        "            report_content.append(\"   ğŸŒŸ ì¶”ì²œ ì…ì§€ ìˆœìœ„ (ìƒìƒì—…ì²´ ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ):\")\n",
        "            for idx, (_, opp) in enumerate(top_opportunities.iterrows(), 1):\n",
        "                report_content.append(f\"      {idx}. {opp['center_school']} ì£¼ë³€ ({opp['district']})\")\n",
        "                report_content.append(f\"         ì´ˆë“±í•™êµ: {opp['nearby_elementary']}ê°œ, ì¤‘í•™êµ: {opp['nearby_middle']}ê°œ\")\n",
        "                report_content.append(f\"         ìƒìƒì—…ì²´: {opp['nearby_supporting']}ê°œ, ê²½ìŸì—…ì²´: {opp['nearby_competitors']}ê°œ\")\n",
        "                report_content.append(\"\")\n",
        "\n",
        "    # 5. ì¢…í•© ê²°ë¡ \n",
        "    report_content.append(\"4ï¸âƒ£ ì¢…í•© ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\")\n",
        "    report_content.append(\"   ğŸ“ˆ ì‹œì¥ í˜„í™©:\")\n",
        "    report_content.append(f\"      - ì„œìš¸ ì§€ì—­ì— ì´ {len(analyzer.competitors)}ê°œ ì½”ë”©í•™ì› ê²½ìŸì—…ì²´ í™•ì¸\")\n",
        "    report_content.append(f\"      - ê²½ìŸì´ ê°€ì¥ ì¹˜ì—´í•œ ì§€ì—­: {district_dist.index[0]} ({district_dist.iloc[0]}ê°œ)\")\n",
        "    report_content.append(\"\")\n",
        "\n",
        "    avg_elementary = df['nearby_elementary'].mean()\n",
        "    avg_supporting = df['total_supporting'].mean()\n",
        "\n",
        "    report_content.append(\"   ğŸ¯ ê¶Œì¥ ì…ì§€ ì „ëµ:\")\n",
        "    report_content.append(f\"      - ì´ˆë“±í•™êµ {avg_elementary:.0f}ê°œ ì´ìƒ ìœ„ì¹˜í•œ ì§€ì—­ ì„ í˜¸\")\n",
        "    report_content.append(f\"      - ìƒìƒì—…ì²´ {avg_supporting:.0f}ê°œ ì´ìƒ ë°€ì§‘ëœ êµìœ¡ í™˜ê²½\")\n",
        "    report_content.append(\"      - ê¸°ì¡´ ê²½ìŸì—…ì²´ê°€ ì—†ê±°ë‚˜ 1ê°œ ì´í•˜ì¸ ì§€ì—­\")\n",
        "\n",
        "    if hasattr(analyzer, 'opportunities_df') and len(analyzer.opportunities_df) > 0:\n",
        "        best_district = analyzer.opportunities_df['district'].value_counts().index[0]\n",
        "        report_content.append(f\"      - ìµœìš°ì„  ê²€í†  ì§€ì—­: {best_district}\")\n",
        "\n",
        "    # ì½˜ì†”ì— ì¶œë ¥\n",
        "    print(\"\\n\".join(report_content))\n",
        "\n",
        "    # íŒŒì¼ ì €ì¥\n",
        "    if save_files:\n",
        "        # 1. í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ì €ì¥\n",
        "        txt_filename = f'ê²½ìŸë¶„ì„ë³´ê³ ì„œ_{timestamp}.txt'\n",
        "        with open(txt_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"\\n\".join(report_content))\n",
        "\n",
        "        # 2. CSV ë°ì´í„° ì €ì¥\n",
        "        csv_filename = f'ê²½ìŸì—…ì²´ë°ì´í„°_{timestamp}.csv'\n",
        "        analyzer.surroundings_df.to_csv(csv_filename, encoding='utf-8-sig', index=False)\n",
        "\n",
        "        # 3. ê¸°íšŒì§€ì—­ CSV ì €ì¥\n",
        "        if hasattr(analyzer, 'opportunities_df') and len(analyzer.opportunities_df) > 0:\n",
        "            opp_filename = f'ì…ì§€ê¸°íšŒì§€ì—­_{timestamp}.csv'\n",
        "            analyzer.opportunities_df.to_csv(opp_filename, encoding='utf-8-sig', index=False)\n",
        "            print(f\"\\nğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ:\")\n",
        "            print(f\"   - ë³´ê³ ì„œ: {txt_filename}\")\n",
        "            print(f\"   - ê²½ìŸì—…ì²´ ë°ì´í„°: {csv_filename}\")\n",
        "            print(f\"   - ê¸°íšŒì§€ì—­ ë°ì´í„°: {opp_filename}\")\n",
        "        else:\n",
        "            print(f\"\\nğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ:\")\n",
        "            print(f\"   - ë³´ê³ ì„œ: {txt_filename}\")\n",
        "            print(f\"   - ê²½ìŸì—…ì²´ ë°ì´í„°: {csv_filename}\")\n",
        "\n",
        "        return txt_filename, csv_filename\n",
        "\n",
        "    return None\n",
        "\n",
        "def create_excel_report(analyzer):\n",
        "    \"\"\"Excel í˜•íƒœì˜ ìƒì„¸ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
        "    try:\n",
        "        import openpyxl\n",
        "        from openpyxl.styles import Font, PatternFill, Alignment\n",
        "        from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "    except ImportError:\n",
        "        print(\"Excel ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•´ openpyxlì„ ì„¤ì¹˜í•˜ì„¸ìš”: !pip install openpyxl\")\n",
        "        return None\n",
        "\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f'ê²½ìŸë¶„ì„_ì¢…í•©ë³´ê³ ì„œ_{timestamp}.xlsx'\n",
        "\n",
        "    # ì›Œí¬ë¶ ìƒì„±\n",
        "    wb = openpyxl.Workbook()\n",
        "\n",
        "    # 1. ìš”ì•½ ì‹œíŠ¸\n",
        "    ws1 = wb.active\n",
        "    ws1.title = \"ë¶„ì„ìš”ì•½\"\n",
        "\n",
        "    # í—¤ë” ìŠ¤íƒ€ì¼\n",
        "    header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
        "    header_font = Font(color=\"FFFFFF\", bold=True)\n",
        "\n",
        "    # ìš”ì•½ ì •ë³´ ì…ë ¥\n",
        "    ws1['A1'] = \"ì½”ë”©í•™ì› ê²½ìŸ ë¶„ì„ ë³´ê³ ì„œ\"\n",
        "    ws1['A1'].font = Font(size=16, bold=True)\n",
        "    ws1['A3'] = f\"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}\"\n",
        "\n",
        "    # ì£¼ìš” ì§€í‘œ\n",
        "    ws1['A5'] = \"ì£¼ìš” ì§€í‘œ\"\n",
        "    ws1['A5'].font = header_font\n",
        "    ws1['A5'].fill = header_fill\n",
        "\n",
        "    df = analyzer.surroundings_df\n",
        "    ws1['A6'] = f\"ì´ ê²½ìŸì—…ì²´ ìˆ˜: {len(analyzer.competitors)}ê°œ\"\n",
        "    ws1['A7'] = f\"í‰ê·  ì£¼ë³€ ì´ˆë“±í•™êµ: {df['nearby_elementary'].mean():.1f}ê°œ, í•™ìƒ ìˆ˜ {df.['']}\"\n",
        "    ws1['A8'] = f\"í‰ê·  ì£¼ë³€ ì¤‘í•™êµ: {df['nearby_middle'].mean():.1f}ê°œ\"\n",
        "    ws1['A9'] = f\"í‰ê·  ì£¼ë³€ ìƒìƒì—…ì²´: {df['total_supporting'].mean():.1f}ê°œ\"\n",
        "\n",
        "    if hasattr(analyzer, 'opportunities_df'):\n",
        "        ws1['A10'] = f\"ë°œêµ´ëœ ê¸°íšŒì§€ì—­: {len(analyzer.opportunities_df)}ê°œ\"\n",
        "\n",
        "    # 2. ê²½ìŸì—…ì²´ ë°ì´í„° ì‹œíŠ¸\n",
        "    ws2 = wb.create_sheet(\"ê²½ìŸì—…ì²´_ìƒì„¸ë°ì´í„°\")\n",
        "\n",
        "    for r in dataframe_to_rows(analyzer.surroundings_df, index=False, header=True):\n",
        "        ws2.append(r)\n",
        "\n",
        "    # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©\n",
        "    for cell in ws2[1]:\n",
        "        cell.font = header_font\n",
        "        cell.fill = header_fill\n",
        "        cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    # 3. ì…ì§€ ê¸°íšŒ ì‹œíŠ¸\n",
        "    if hasattr(analyzer, 'opportunities_df') and len(analyzer.opportunities_df) > 0:\n",
        "        ws3 = wb.create_sheet(\"ì…ì§€ê¸°íšŒ_ì§€ì—­\")\n",
        "\n",
        "        for r in dataframe_to_rows(analyzer.opportunities_df, index=False, header=True):\n",
        "            ws3.append(r)\n",
        "\n",
        "        for cell in ws3[1]:\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    # 4. êµ¬ë³„ í†µê³„ ì‹œíŠ¸\n",
        "    ws4 = wb.create_sheet(\"êµ¬ë³„_í†µê³„\")\n",
        "\n",
        "    # ê²½ìŸì—…ì²´ êµ¬ë³„ ë¶„í¬\n",
        "    district_stats = analyzer.competitors['district'].value_counts().reset_index()\n",
        "    district_stats.columns = ['êµ¬', 'ê²½ìŸì—…ì²´_ìˆ˜']\n",
        "\n",
        "    # ê¸°íšŒì§€ì—­ êµ¬ë³„ ë¶„í¬ ì¶”ê°€\n",
        "    if hasattr(analyzer, 'opportunities_df') and len(analyzer.opportunities_df) > 0:\n",
        "        opp_stats = analyzer.opportunities_df['district'].value_counts().reset_index()\n",
        "        opp_stats.columns = ['êµ¬', 'ê¸°íšŒì§€ì—­_ìˆ˜']\n",
        "        district_stats = district_stats.merge(opp_stats, on='êµ¬', how='left')\n",
        "        district_stats['ê¸°íšŒì§€ì—­_ìˆ˜'] = district_stats['ê¸°íšŒì§€ì—­_ìˆ˜'].fillna(0)\n",
        "\n",
        "    for r in dataframe_to_rows(district_stats, index=False, header=True):\n",
        "        ws4.append(r)\n",
        "\n",
        "    for cell in ws4[1]:\n",
        "        cell.font = header_font\n",
        "        cell.fill = header_fill\n",
        "        cell.alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "    # íŒŒì¼ ì €ì¥\n",
        "    wb.save(filename)\n",
        "    print(f\"ğŸ“Š Excel ë³´ê³ ì„œ ì €ì¥: {filename}\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "def download_all_files():\n",
        "    \"\"\"ëª¨ë“  ìƒì„±ëœ íŒŒì¼ì„ í•œë²ˆì— ë‹¤ìš´ë¡œë“œ\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        import glob\n",
        "\n",
        "        # ìƒì„±ëœ ëª¨ë“  íŒŒì¼ ì°¾ê¸°\n",
        "        report_files = glob.glob(\"ê²½ìŸë¶„ì„*.txt\")\n",
        "        csv_files = glob.glob(\"ê²½ìŸì—…ì²´*.csv\") + glob.glob(\"ì…ì§€ê¸°íšŒ*.csv\")\n",
        "        excel_files = glob.glob(\"ê²½ìŸë¶„ì„*.xlsx\")\n",
        "        map_files = glob.glob(\"*map.html\")\n",
        "\n",
        "        all_files = report_files + csv_files + excel_files + map_files\n",
        "\n",
        "        print(\"ğŸ“ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ë“¤:\")\n",
        "        for file in all_files:\n",
        "            print(f\"   - {file}\")\n",
        "\n",
        "        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "        for file in all_files:\n",
        "            try:\n",
        "                files.download(file)\n",
        "                print(f\"âœ… {file} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ {file} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Google Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. ë¡œì»¬ì—ì„œ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")"
      ],
      "metadata": {
        "id": "GmUpXgrLt7Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. ì‹¤í–‰"
      ],
      "metadata": {
        "id": "3HifGMEruQ-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # ì „ì²´ ë¶„ì„ ì‹¤í–‰\n",
        "    analyzer = run_complete_analysis()\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥\n",
        "    generate_detailed_report(analyzer, save_files=True)\n",
        "\n",
        "    # Excel ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)\n",
        "    try:\n",
        "        create_excel_report(analyzer)\n",
        "    except Exception as e:\n",
        "        print(f\"Excel ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "    # ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ (Colabìš©)\n",
        "    download_all_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "axmlkK1CklvD",
        "outputId": "d160737d-d258-4a76-869b-99b72ec69c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í•™êµ ë°ì´í„°: 992ê°œ\n",
            "í•™ì› ë°ì´í„°: 24295ê°œ\n",
            "ì„œìš¸íŠ¹ë³„ì‹œ ì´ˆì¤‘í•™êµ: 992ê°œ\n",
            "ì„œìš¸íŠ¹ë³„ì‹œ í•™ì›: 24295ê°œ\n",
            "ê²½ìŸì—…ì²´: 252ê°œ\n",
            "ìƒìƒì—…ì²´: 8365ê°œ\n",
            "ê¸°íƒ€: 15678ê°œ\n",
            "\n",
            "ğŸ”´ ê²½ìŸì—…ì²´ ìƒ˜í”Œ:\n",
            "   - ì„œìš¸ê²Œì„êµìŠµì†Œ (ê²Œì„)\n",
            "   - ì—ì´ë¸”ë””ì½”ë”©ì»´í“¨í„°êµìŠµì†Œ (nan)\n",
            "   - ì „ìë°•ì‚¬ë¡œë´‡êµì‹¤ë¡œë´‡êµìŠµì†Œ (ë¡œë´‡)\n",
            "\n",
            "ğŸŸ¢ ìƒìƒì—…ì²´ ìƒ˜í”Œ:\n",
            "   - GLMAê¸€ë¡œë²Œì¸ìƒë§Œë‚¨ë…¼ìˆ êµìŠµì†Œ (ë³´ìŠµÂ·ë…¼ìˆ )\n",
            "   - Jë°”ì´ì˜¬ë¦°ìŒì•…êµìŠµì†Œ (ìŒì•…)\n",
            "   - SCMAìŒì•…êµìŠµì†Œ (ìŒì•…)\n",
            "\n",
            "ğŸ” ê²½ìŸì—…ì²´ ì£¼ë³€ í™˜ê²½ ë¶„ì„ ì¤‘...\n",
            "==================================================\n",
            "ğŸ¢ ê²½ìŸì—…ì²´ ì£¼ë³€ í™˜ê²½ ë¶„ì„ ê²°ê³¼\n",
            "==================================================\n",
            "\n",
            "ğŸ“ ë¶„ì„ ëŒ€ìƒ: 252ê°œ ê²½ìŸì—…ì²´ (ë°˜ê²½ 1km ê¸°ì¤€)\n",
            "\n",
            "ğŸ« ì£¼ë³€ í•™êµ í˜„í™©:\n",
            "   â€¢ í‰ê·  ì´ˆë“±í•™êµ: 4.3ê°œ, í•™ìƒ ìˆ˜ 3073.1746031746034ëª…\n",
            "   â€¢ í‰ê·  ì¤‘í•™êµ: 2.9ê°œ, í•™ìƒ ìˆ˜ 1796.7539682539682ëª…\n",
            "   â€¢ í‰ê·  ì´ í•™êµ ìˆ˜: 7.2ê°œ\n",
            "\n",
            "ğŸ“ ì£¼ë³€ ìƒìƒì—…ì²´ í˜„í™©:\n",
            "   â€¢ í‰ê·  ìŒì•…í•™ì›: 33.7ê°œ\n",
            "   â€¢ í‰ê·  íƒœê¶Œë„í•™ì›: 11.6ê°œ\n",
            "   â€¢ í‰ê·  ë…¼ìˆ í•™ì›: 68.2ê°œ\n",
            "   â€¢ í‰ê·  ë°”ë‘‘/ì£¼ì‚°í•™ì›: 0.9ê°œ\n",
            "   â€¢ í‰ê·  ì´ ìƒìƒì—…ì²´: 114.6ê°œ\n",
            "\n",
            "âœ… ìµœì  ì…ì§€ ì¡°ê±´ (50%):\n",
            "   â€¢ ì´ˆë“±í•™êµ 4ê°œ ì´ìƒ, ì´ˆë“±í•™ìƒ ìˆ˜ 2910ëª… ì´ìƒ\n",
            "   â€¢ ì¤‘í•™êµ 3ê°œ ì´ìƒ, ì¤‘í•™ìƒ ìˆ˜ 1520ëª… ì´ìƒ\n",
            "   â€¢ ìƒìƒì—…ì²´ 70ê°œ ì´ìƒ\n",
            "\n",
            "ğŸ¯ ì…ì§€ ê¸°íšŒ ë°œêµ´ ì¤‘...\n",
            "\n",
            "ğŸ¯ ë°œêµ´ëœ ì…ì§€ ê¸°íšŒ: 41ê°œ ì§€ì—­\n",
            "\n",
            "ğŸ“Š ê¸°íšŒ ì§€ì—­ ë¶„í¬:\n",
            "   â€¢ ì„±ë¶êµ¬: 10ê°œ\n",
            "   â€¢ ì†¡íŒŒêµ¬: 5ê°œ\n",
            "   â€¢ ì–‘ì²œêµ¬: 4ê°œ\n",
            "   â€¢ ê°•ë™êµ¬: 4ê°œ\n",
            "   â€¢ ê°•ë¶êµ¬: 4ê°œ\n",
            "   â€¢ ê°•ë‚¨êµ¬: 3ê°œ\n",
            "   â€¢ ë„ë´‰êµ¬: 2ê°œ\n",
            "   â€¢ ì˜ë“±í¬êµ¬: 2ê°œ\n",
            "   â€¢ ë™ì‘êµ¬: 2ê°œ\n",
            "   â€¢ ê°•ì„œêµ¬: 1ê°œ\n",
            "\n",
            "ğŸ—ºï¸ ì¢…í•© ë¶„ì„ ì§€ë„ ìƒì„± ì¤‘...\n",
            "\n",
            "âœ… ë¶„ì„ ì™„ë£Œ!\n",
            "ğŸ“ íŒŒì¼ ì €ì¥: competitor_analysis_map.html\n",
            "============================================================\n",
            "ğŸ“Š ì½”ë”©í•™ì› ê²½ìŸ ë¶„ì„ ë³´ê³ ì„œ\n",
            "============================================================\n",
            "ğŸ“… ìƒì„±ì¼ì‹œ: 2025ë…„ 07ì›” 17ì¼ 10ì‹œ 30ë¶„\n",
            "\n",
            "1ï¸âƒ£ ê²½ìŸì—…ì²´ í˜„í™©\n",
            "   ì´ 252ê°œ ê²½ìŸì—…ì²´ í™•ì¸\n",
            "\n",
            "   ğŸ“ êµ¬ë³„ ê²½ìŸì—…ì²´ ë¶„í¬ (ìƒìœ„ 10ê°œ):\n",
            "      ê°•ë‚¨êµ¬: 54ê°œ\n",
            "      ì„œì´ˆêµ¬: 22ê°œ\n",
            "      ë§ˆí¬êµ¬: 22ê°œ\n",
            "      ì†¡íŒŒêµ¬: 18ê°œ\n",
            "      ì–‘ì²œêµ¬: 18ê°œ\n",
            "      êµ¬ë¡œêµ¬: 13ê°œ\n",
            "      ë…¸ì›êµ¬: 12ê°œ\n",
            "      ì¢…ë¡œêµ¬: 10ê°œ\n",
            "      ì€í‰êµ¬: 9ê°œ\n",
            "      ê°•ë™êµ¬: 8ê°œ\n",
            "\n",
            "2ï¸âƒ£ ê²½ìŸì—…ì²´ í‰ê·  ì…ì§€ í™˜ê²½ (ë°˜ê²½ 1km ê¸°ì¤€)\n",
            "   ğŸ« ì£¼ë³€ í•™êµ:\n",
            "      - í‰ê·  ì´ˆë“±í•™êµ: 4.3ê°œ\n",
            "      - í‰ê·  ì¤‘í•™êµ: 2.9ê°œ\n",
            "      - í‰ê·  ì´ í•™êµ: 7.2ê°œ\n",
            "\n",
            "   ğŸ“ ì£¼ë³€ ìƒìƒì—…ì²´:\n",
            "      - í‰ê·  ìŒì•…í•™ì›: 33.7ê°œ\n",
            "      - í‰ê·  íƒœê¶Œë„í•™ì›: 11.6ê°œ\n",
            "      - í‰ê·  ë…¼ìˆ í•™ì›: 68.2ê°œ\n",
            "      - í‰ê·  ë°”ë‘‘í•™ì›: 0.9ê°œ\n",
            "      - í‰ê·  ì´ ìƒìƒì—…ì²´: 114.6ê°œ\n",
            "\n",
            "   âœ… ìµœì  ì…ì§€ ì¡°ê±´ (ê²½ìŸì—…ì²´ 50% ìˆ˜ì¤€):\n",
            "      - ì´ˆë“±í•™êµ 3ê°œ ì´ìƒ\n",
            "      - ì¤‘í•™êµ 2ê°œ ì´ìƒ\n",
            "      - ìƒìƒì—…ì²´ 51ê°œ ì´ìƒ\n",
            "\n",
            "3ï¸âƒ£ ì…ì§€ ê¸°íšŒ ì§€ì—­\n",
            "   ğŸ¯ ì´ 41ê°œ ê¸°íšŒ ì§€ì—­ ë°œêµ´\n",
            "      (ìµœì  ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ ê²½ìŸì—…ì²´ê°€ 1ê°œ ì´í•˜ì¸ ì§€ì—­)\n",
            "\n",
            "   ğŸ“ êµ¬ë³„ ê¸°íšŒ ì§€ì—­ ë¶„í¬:\n",
            "      ì„±ë¶êµ¬: 10ê°œ\n",
            "      ì†¡íŒŒêµ¬: 5ê°œ\n",
            "      ì–‘ì²œêµ¬: 4ê°œ\n",
            "      ê°•ë™êµ¬: 4ê°œ\n",
            "      ê°•ë¶êµ¬: 4ê°œ\n",
            "      ê°•ë‚¨êµ¬: 3ê°œ\n",
            "      ë„ë´‰êµ¬: 2ê°œ\n",
            "      ì˜ë“±í¬êµ¬: 2ê°œ\n",
            "      ë™ì‘êµ¬: 2ê°œ\n",
            "      ê°•ì„œêµ¬: 1ê°œ\n",
            "\n",
            "   ğŸŒŸ ì¶”ì²œ ì…ì§€ ìˆœìœ„ (ìƒìƒì—…ì²´ ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ):\n",
            "      1. ìˆ­ê³¡ì¤‘í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 7ê°œ, ì¤‘í•™êµ: 4ê°œ\n",
            "         ìƒìƒì—…ì²´: 134ê°œ, ê²½ìŸì—…ì²´: 0ê°œ\n",
            "\n",
            "      2. ì„œìš¸ì •ë•ì´ˆë“±í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 7ê°œ, ì¤‘í•™êµ: 4ê°œ\n",
            "         ìƒìƒì—…ì²´: 130ê°œ, ê²½ìŸì—…ì²´: 1ê°œ\n",
            "\n",
            "      3. ê³ ëª…ì¤‘í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 7ê°œ, ì¤‘í•™êµ: 3ê°œ\n",
            "         ìƒìƒì—…ì²´: 129ê°œ, ê²½ìŸì—…ì²´: 1ê°œ\n",
            "\n",
            "      4. ì„œìš¸ë¯¸ì•„ì´ˆë“±í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 6ê°œ, ì¤‘í•™êµ: 4ê°œ\n",
            "         ìƒìƒì—…ì²´: 129ê°œ, ê²½ìŸì—…ì²´: 1ê°œ\n",
            "\n",
            "      5. ë§¤ì›ì´ˆë“±í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 7ê°œ, ì¤‘í•™êµ: 3ê°œ\n",
            "         ìƒìƒì—…ì²´: 129ê°œ, ê²½ìŸì—…ì²´: 1ê°œ\n",
            "\n",
            "      6. ì„œìš¸ìˆ­ê³¡ì´ˆë“±í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 5ê°œ, ì¤‘í•™êµ: 4ê°œ\n",
            "         ìƒìƒì—…ì²´: 125ê°œ, ê²½ìŸì—…ì²´: 0ê°œ\n",
            "\n",
            "      7. ì˜í›ˆì´ˆë“±í•™êµ ì£¼ë³€ (ê°•ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 5ê°œ, ì¤‘í•™êµ: 5ê°œ\n",
            "         ìƒìƒì—…ì²´: 122ê°œ, ê²½ìŸì—…ì²´: 0ê°œ\n",
            "\n",
            "      8. ì˜í›ˆêµ­ì œì¤‘í•™êµ ì£¼ë³€ (ê°•ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 5ê°œ, ì¤‘í•™êµ: 5ê°œ\n",
            "         ìƒìƒì—…ì²´: 122ê°œ, ê²½ìŸì—…ì²´: 0ê°œ\n",
            "\n",
            "      9. ì„œìš¸ëˆì•”ì´ˆë“±í•™êµ ì£¼ë³€ (ì„±ë¶êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 6ê°œ, ì¤‘í•™êµ: 5ê°œ\n",
            "         ìƒìƒì—…ì²´: 121ê°œ, ê²½ìŸì—…ì²´: 0ê°œ\n",
            "\n",
            "      10. ì„œìš¸ì²œí˜¸ì´ˆë“±í•™êµ ì£¼ë³€ (ê°•ë™êµ¬)\n",
            "         ì´ˆë“±í•™êµ: 5ê°œ, ì¤‘í•™êµ: 5ê°œ\n",
            "         ìƒìƒì—…ì²´: 112ê°œ, ê²½ìŸì—…ì²´: 1ê°œ\n",
            "\n",
            "4ï¸âƒ£ ì¢…í•© ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n",
            "   ğŸ“ˆ ì‹œì¥ í˜„í™©:\n",
            "      - ì„œìš¸ ì§€ì—­ì— ì´ 252ê°œ ì½”ë”©í•™ì› ê²½ìŸì—…ì²´ í™•ì¸\n",
            "      - ê²½ìŸì´ ê°€ì¥ ì¹˜ì—´í•œ ì§€ì—­: ê°•ë‚¨êµ¬ (54ê°œ)\n",
            "\n",
            "   ğŸ¯ ê¶Œì¥ ì…ì§€ ì „ëµ:\n",
            "      - ì´ˆë“±í•™êµ 4ê°œ ì´ìƒ ìœ„ì¹˜í•œ ì§€ì—­ ì„ í˜¸\n",
            "      - ìƒìƒì—…ì²´ 115ê°œ ì´ìƒ ë°€ì§‘ëœ êµìœ¡ í™˜ê²½\n",
            "      - ê¸°ì¡´ ê²½ìŸì—…ì²´ê°€ ì—†ê±°ë‚˜ 1ê°œ ì´í•˜ì¸ ì§€ì—­\n",
            "      - ìµœìš°ì„  ê²€í†  ì§€ì—­: ì„±ë¶êµ¬\n",
            "\n",
            "ğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ:\n",
            "   - ë³´ê³ ì„œ: ê²½ìŸë¶„ì„ë³´ê³ ì„œ_20250717_103029.txt\n",
            "   - ê²½ìŸì—…ì²´ ë°ì´í„°: ê²½ìŸì—…ì²´ë°ì´í„°_20250717_103029.csv\n",
            "   - ê¸°íšŒì§€ì—­ ë°ì´í„°: ì…ì§€ê¸°íšŒì§€ì—­_20250717_103029.csv\n",
            "Excel ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: Cannot convert [{'name': 'ì„œìš¸ì–¸ë¶ì´ˆë“±í•™êµ', 'type': 'ì´ˆë“±í•™êµ', 'count': 1528, 'distance': 0.8275198500559696}, {'name': 'ì„œìš¸ì²­ë‹´ì´ˆë“±í•™êµ', 'type': 'ì´ˆë“±í•™êµ', 'count': 436, 'distance': 0.4486685600695685}, {'name': 'ì²­ë‹´ì¤‘í•™êµ', 'type': 'ì¤‘í•™êµ', 'count': 340, 'distance': 0.4953136719334377}] to Excel\n",
            "ğŸ“ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ë“¤:\n",
            "   - ê²½ìŸë¶„ì„ë³´ê³ ì„œ_20250717_103029.txt\n",
            "   - ê²½ìŸì—…ì²´ë°ì´í„°_20250717_103029.csv\n",
            "   - ì…ì§€ê¸°íšŒì§€ì—­_20250717_103029.csv\n",
            "   - competitor_analysis_map.html\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3288ec0-68b3-4c1e-978e-21e97d74d1bd\", \"\\uacbd\\uc7c1\\ubd84\\uc11d\\ubcf4\\uace0\\uc11c_20250717_103029.txt\", 3504)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ê²½ìŸë¶„ì„ë³´ê³ ì„œ_20250717_103029.txt ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0105b833-183f-43fc-9d99-00063bc04e17\", \"\\uacbd\\uc7c1\\uc5c5\\uccb4\\ub370\\uc774\\ud130_20250717_103029.csv\", 3017338)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ê²½ìŸì—…ì²´ë°ì´í„°_20250717_103029.csv ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a18d6bb-a653-45d0-8c25-4c664967f509\", \"\\uc785\\uc9c0\\uae30\\ud68c\\uc9c0\\uc5ed_20250717_103029.csv\", 7445)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì…ì§€ê¸°íšŒì§€ì—­_20250717_103029.csv ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78c89a83-51f7-489e-949f-6bd92adb9e96\", \"competitor_analysis_map.html\", 10690818)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… competitor_analysis_map.html ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ì›ë¦¬   \n",
        "1. í•´ë‹¹ í‚¤ì›Œë“œë¥¼ ê°€ì§„ ì—…ì²´ë¥¼ ê²½ìŸ ì—…ì²´ë¡œ ì„ ì •í•´ì„œ ê²½ìŸì—…ì²´ ì§€ë„ ë§Œë“¤ê¸°   \n",
        "2. í•´ë‹¹ ê²½ìŸì—…ì²´ë“¤ ì£¼ë³€ì— ë³´í†µ í•™êµ ë° ë‹¤ë¥¸ í•™ì›ì´ ë¬´ì—‡ì´ ìˆëŠ”ì§€, ì£¼ë³€ì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ ë¶„ì„+ì§€ë„í™” (ex. ê²½ìŸì—…ì²´ ì£¼ë³€ì—ëŠ” í‰ê· ì ìœ¼ë¡œ ì´ˆë“±í•™êµ 2ê°œì™€ ì˜ì–´í•™ì›, í”¼ì•„ë…¸í•™ì›, íƒœê¶Œë„í•™ì›ì´ ìˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ê²°ë¡ ì´ ë‚˜ì™€ì•¼í•¨)   \n",
        "3. 2ë²ˆê°™ì€ í™˜ê²½ì´ ìˆì§€ë§Œ ì•„ì§ ê²½ìŸì—…ì²´(ì»´í“¨í„°, ì½”ë”©í•™ì›)ì´ ë“¤ì–´ì„œì§€ ì•Šì€ ì…ì§€ ì¶”ì¶œ   \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "ğŸ¯ ì‹œìŠ¤í…œ ê¸°ëŠ¥ ê°œìš”\n",
        "1ë‹¨ê³„: ê²½ìŸì—…ì²´ ì§€ë„ ìƒì„± ğŸ”´\n",
        "\n",
        "ì½”ë”©/ì»´í“¨í„° í•™ì›ë“¤ì„ ê²½ìŸì—…ì²´ë¡œ ë¶„ë¥˜\n",
        "ë¹¨ê°„ìƒ‰ ë§ˆì»¤ë¡œ ì§€ë„ì— í‘œì‹œ==\n",
        "ê²½ìŸì—…ì²´ í˜„í™© íŒŒì•…\n",
        "\n",
        "2ë‹¨ê³„: ì£¼ë³€ í™˜ê²½ ë¶„ì„ ğŸ“Š\n",
        "\n",
        "ê° ê²½ìŸì—…ì²´ ë°˜ê²½ 1km ë‚´ í™˜ê²½ ë¶„ì„\n",
        "ìë™ ê³„ì‚°:\n",
        "\n",
        "ì£¼ë³€ ì´ˆë“±í•™êµ/ì¤‘í•™êµ ê°œìˆ˜\n",
        "ì£¼ë³€ ìƒìƒì—…ì²´ (ì˜ì–´, ìˆ˜í•™, í”¼ì•„ë…¸, íƒœê¶Œë„, ë…¼ìˆ í•™ì›) ê°œìˆ˜\n",
        "\n",
        "\n",
        "ê²°ë¡  ë„ì¶œ: \"ê²½ìŸì—…ì²´ ì£¼ë³€ì—ëŠ” í‰ê· ì ìœ¼ë¡œ ì´ˆë“±í•™êµ Xê°œ, ì¤‘í•™êµ Yê°œ, ì˜ì–´í•™ì› Zê°œê°€ ìˆë‹¤\"\n",
        "\n",
        "3ë‹¨ê³„: ì…ì§€ ê¸°íšŒ ë°œêµ´ â­   \n",
        "\n",
        "2ë‹¨ê³„ì—ì„œ ë„ì¶œí•œ ìµœì  í™˜ê²½ ì¡°ê±´ì„ ê¸°ì¤€ìœ¼ë¡œ\n",
        "ì•„ì§ ê²½ìŸì—…ì²´ê°€ ì—†ê±°ë‚˜ ì ì€ ì§€ì—­ ì¤‘ì—ì„œ\n",
        "ìµœì  ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì…ì§€ ê¸°íšŒ ìë™ ì¶”ì¶œ\n",
        "ê³¨ë“œ ìŠ¤íƒ€ ë§ˆì»¤ë¡œ í‘œì‹œ   \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "ğŸ—ºï¸ ì§€ë„ ë ˆì´ì–´ êµ¬ì„±\n",
        "\n",
        "ğŸ« ì´ˆì¤‘í•™êµ: íŒŒë€ìƒ‰/ì´ˆë¡ìƒ‰ ì›í˜• ë§ˆì»¤   \n",
        "ğŸ”´ ê²½ìŸì—…ì²´: ë¹¨ê°„ìƒ‰ ë…¸íŠ¸ë¶ ì•„ì´ì½˜   \n",
        "ğŸŸ¢ ìƒìƒì—…ì²´: ì‘ì€ ìƒ‰ìƒë³„ ì›í˜• ë§ˆì»¤ (ìƒ˜í”Œ)   \n",
        "â­ ì…ì§€ ê¸°íšŒ: ê³¨ë“œ ìŠ¤íƒ€ ì•„ì´ì½˜      \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "ğŸ“Š ì¶”ê°€ ë¶„ì„ ê¸°ëŠ¥\n",
        "ì½”ë“œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:   \n",
        "\n",
        "êµ¬ë³„ ê²½ìŸì—…ì²´ ë°€ë„ ë¶„ì„   \n",
        "ìµœì  ì…ì§€ ì¡°ê±´ ìë™ ê³„ì‚° (í•˜ìœ„ 25% ê¸°ì¤€)   \n",
        "ê±°ë¦¬ ê¸°ë°˜ í™˜ê²½ ë¶„ì„ (geopy í™œìš©x ë” ë¹ ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì”€)   \n",
        "ìƒìƒì—…ì²´ ì„¸ë¶€ ë¶„ë¥˜ (í”¼ì•„ë…¸, ë…¼ìˆ  ë“±)   \n",
        "ê¸°íšŒ ì§€ì—­ ìš°ì„ ìˆœìœ„ ë­í‚¹     \n"
      ],
      "metadata": {
        "id": "8X5x4pmjgIE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì—­ ê¸°ì¤€ ì•ˆí• ê±°ì„ ì–´ì°¨í”¼ ì´ˆë“±í•™ìƒì´ë©´ ì—­ë³´ë‹¤ ì´ˆë“±í•™êµ&ì£¼ê±°ì§€ ì¸ê·¼ì´ í›¨ì”¬ ì ‘ê·¼ì„±ì´ ì¢‹ì„ ê²ƒ ê°™ìŒ.\n",
        "\n",
        "íƒœê¶Œë„ í¬í•¨í•¨\n",
        "\n",
        "^.^ íŒŒì´íŒ…"
      ],
      "metadata": {
        "id": "uO_KYpre94ed"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyugqapjCZf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}